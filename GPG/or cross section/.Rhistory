#Determine truncation points - we want to take away the extremes, inspecting data
#we deemed bottom and top 10% was best
truncation_points <- quantile(joint_distribution, c(0.1, 0.9))
#Truncate the joint normal distribution by creating a matrix and looping the r truncnorm function
truncated_distribution <- matrix(NA, nrow = sample_size, ncol = 2)
for (i in 1:2) {
truncated_distribution[, i] <- rtruncnorm(n = sample_size, a = truncation_points[i], b = Inf,
mean = sample_meanvector[i], sd = sqrt(sample_covariance_matrix1[i,i]))
}
#Calculate the ATT using a normal distribution model
y_treated <- rnorm(n = prop_treated * sample_size, mean = U1, sd = sqrt(C))
y_control <- rnorm(n = (1 - prop_treated) * sample_size, mean = U0, sd = sqrt(C))
ATE <- mean(y_treated) - mean(y_control)
ATT <- mean(truncated_distribution[1:prop_treated * sample_size, 1]) - mean(truncated_distribution[1:(1 - prop_treated) * sample_size, 2])
cat("ATE:", round(ATE, 2), "\n") #ATE = 2
cat("ATT:", round(ATT, 2)) #ATT = -0.3
library(sf)
library(terra)
library(Spdata)
install.packages("spDataLarge", repos = "https://nowosad.r-universe.dev")
library(spData)
library(sf)
library(terra)
library(spData)
install.packages("spDataLarge", repos = "https://nowosad.r-universe.dev")
install.packages("spdatalarge")
library(sf)
library(terra)
library(spData)
install.packages("spdatalarge")
vignette(package = "sf") # see which vignettes are available
vignette("sf1")          # an introduction to the package
class(world)
class(world)
names(world)
world$geom
install.packages("spdatalarge")
install.packages("spDataLarge", repos = "https://nowosad.r-universe.dev")
install.packages("Rtools")
library(spDataLarge)   # load larger geographic data
install.packages("spDataLarge", repos = "https://nowosad.r-universe.dev")
library(spDataLarge)   # load larger geographic data
vignette(package = "sf") # see which vignettes are available
vignette("sf1")          # an introduction to the package
class(world)
names(world)
plot(world)
devtools::install_github("synth-inference/synthdid")
library(synthdid)
# Estimate the effect of California Proposition 99 on cigarette consumption
data('california_prop99')
force(california_prop99)
View(california_prop99)
rm(list = ls())
library(synthdid)
rm(list = ls())
# Estimate the effect of California Proposition 99 on cigarette consumption
data('california_prop99')
force(california_prop99)
View(california_prop99)
setup = panel.matrices(california_prop99)
View(setup)
tau.hat = synthdid_estimate(setup$Y, setup$N0, setup$T0)
tau.hat
setup = panel.matrices(california_prop99)
tau.hat = synthdid_estimate(setup$Y, setup$N0, setup$T0)
se = sqrt(vcov(tau.hat, method='placebo'))
sprintf('point estimate: %1.2f', tau.hat)
sprintf('95%% CI (%1.2f, %1.2f)', tau.hat - 1.96 * se, tau.hat + 1.96 * se)
plot(tau.hat)
library(ggplot2)
library(ggplot2)
data(california_prop99)
california_prop99$date = as.Date(sprintf('%04d/%02d/%02d', california_prop99$Year, 1, 1))
setup = panel.matrices(california_prop99[! california_prop99$Year %in%  c(1974:1977, 1989:1992),], time='date')
estimate = synthdid_estimate(setup$Y, setup$N0, setup$T0)
plot(estimate)
library(synthdid)
library(MCPanel)
install.packages("MCpanel")
install.packages("rngtools")
install.packages("future")
install.packages("doFuture")
install.packages("future.batchtools")
library(synthdid)
library(MCPanel)
library(rngtools)
library(future)
library(doFuture)
library(future.batchtools)
install.packages("readstata13")
library(xtable)
library(dplyr)
library(tidyr)
library(tibble)
library(ggplot2)
mc_estimate = function(Y, N0, T0) {
N1=nrow(Y)-N0
T1=ncol(Y)-T0
W <- outer(c(rep(0,N0),rep(1,N1)),c(rep(0,T0),rep(1,T1)))
mc_pred <- mcnnm_cv(Y, 1-W, num_lam_L = 20)
mc_fit  <- mc_pred$L + outer(mc_pred$u, mc_pred$v, '+')
mc_est <- sum(W*(Y-mc_fit))/sum(W)
mc_est
}
mc_placebo_se = function(Y, N0, T0, replications=200) {
N1 = nrow(Y) - N0
theta = function(ind) { mc_estimate(Y[ind,], length(ind)-N1, T0) }
sqrt((replications-1)/replications) * sd(replicate(replications, theta(sample(1:N0))))
}
difp_estimate = function(Y, N0, T0) {
synthdid_estimate(Y, N0, T0, weights=list(lambda=rep(1/T0, T0)), eta.omega=1e-6)
}
sc_estimate_reg = function(Y, N0, T0) {
sc_estimate(Y, N0, T0, eta.omega=((nrow(Y)-N0)*(ncol(Y)-T0))^(1/4))
}
difp_estimate_reg = function(Y, N0, T0) {
synthdid_estimate(Y, N0, T0, weights=list(lambda=rep(1/T0, T0)))
}
estimators = list(did=did_estimate,
sc=sc_estimate,
sdid=synthdid_estimate,
difp=difp_estimate,
mc = mc_estimate,
sc_reg = sc_estimate_reg,
difp_reg = difp_estimate_reg)
data('california_prop99')
setup = panel.matrices(california_prop99)
estimates = lapply(estimators, function(estimator) { estimator(setup$Y, setup$N0, setup$T0) } )
standard.errors = mapply(function(estimate, name) {
set.seed(12345)
if(name == 'mc') { mc_placebo_se(setup$Y, setup$N0, setup$T0) }
else {             sqrt(vcov(estimate, method='placebo'))     }
}, estimates, names(estimators))
estimators = list(did=did_estimate,
sc=sc_estimate,
sdid=synthdid_estimate,
difp=difp_estimate,
mc = mc_estimate,
sc_reg = sc_estimate_reg,
difp_reg = difp_estimate_reg)
data('california_prop99')
setup = panel.matrices(california_prop99)
estimates = lapply(estimators, function(estimator) { estimator(setup$Y, setup$N0, setup$T0) } )
library(MCPanel)
install.packages("remotes")
install.packages("remotes")
remotes::install_github("susanathey/MCPanel")
install.packages("remotes")
remotes::install_github("susanathey/MCPanel")
remotes::install_github("susanathey/MCPanel")
install.packages("devtools")
install.packages("latex2exp")
library(devtools)
install_github("susanathey/MCPanel")
install_github("susanathey/MCPanel")
force = TRUE
install.packages("did")
library(did)
data(mpdta)
force(mpdta)
out <- att_gt(yname = "lemp",
gname = "first.treat",
idname = "countyreal",
tname = "year",
xformla = ~1,
data = mpdta,
est_method = "reg"
)
att_g
library(did)
data(mpdta) #contains 500 observations of county-level teen employment rates from 2003-2007. Some states are first treated in 2004, some in 2006, and some in 2007
rm(tmp)
rm(list = ls())
data(mpdta) #contains 500 observations of county-level teen employment rates from 2003-2007. Some states are first treated in 2004, some in 2006, and some in 2007
out <- att_gt(yname = "lemp", #log of county level teen employment
gname = "first.treat", #the period when a state first increases its min wage 04/6/7
idname = "countyreal", #an id number for each county and provides the indiviudal identifier in this panel data context
tname = "year", #year and time variable
xformla = ~1,
data = mpdta,
est_method = "reg"
)
#att_gt returns a class MP object that has a lot of information but mainly estimates of group-time average treatment
#effects and their standard errors
summary(out)
#this provides estimates of group-time average treatment effects for all groups in all time
#periods. group time average treatment effect are identified when t >= g (post treatment time periods
#for each group), but summary reports them even in periods when t < g - these can be used to pre - test
#the parallel trends assumption. the p value for pre test of parallel trends assumption is for a Wald
#pre - test of the parallel trends assumption. here the parallel trends assumption would not be rejected at conventional
#significance levels
ggdid(out)
#this provides estimates of group-time average treatment effects for all groups in all time
#periods. group time average treatment effect are identified when t >= g (post treatment time periods
#for each group), but summary reports them even in periods when t < g - these can be used to pre - test
#the parallel trends assumption. the p value for pre test of parallel trends assumption is for a Wald
#pre - test of the parallel trends assumption. here the parallel trends assumption would not be rejected at conventional
#significance levels
ggdid(out, ylim = c(-.25,.1))
es <- aggte(out, type = "dynamic")
summary(es)
#the column event time is for each group relative to when they first participate in treatment,
#event time=0 corresponds to the on impact effect and event time = -1 is the effect in the period before a unit
#becomes treated (checking that this is euqal to 0 is potentially useful as a pre-test)
ggdid(es)
#to compute thuis overall treatment effect parameter:
group_effects <- aggte(out, type = "group")
summary(group_effects)
#synthetic controls
#misc proj synthetic control
library(tidyverse)
library(haven)
library(Synth)
library(devtools)
library(SCtools)
#synthetic controls
#misc proj synthetic control
library(tidyverse)
library(haven)
library(Synth)
library(devtools)
library(SCtools)
read_data <- function(df)
{
full_path <- paste("https://github.com/scunning1975/mixtape/raw/master/",
df, sep = "")
df <- read_dta(full_path)
return(df)
}
texas <- read_data("texas.dta") %>%
as.data.frame(.)
dataprep_out <- dataprep(
foo = texas,
predictors = c("poverty", "income"),
predictors.op = "mean",
time.predictors.prior = 1985:1993,
special.predictors = list(
list("bmprison", c(1988, 1990:1992), "mean"),
list("alcohol", 1990, "mean"),
list("aidscapita", 1990:1991, "mean"),
list("black", 1990:1992, "mean"),
list("perc1519", 1990, "mean")),
dependent = "bmprison",
unit.variable = "statefip",
unit.names.variable = "state",
time.variable = "year",
treatment.identifier = 48,
controls.identifier = c(1,2,4:6,8:13,15:42,44:47,49:51,53:56),
time.optimize.ssr = 1985:1993,
time.plot = 1985:2000
)
synth_out <- synth(data.prep.obj = dataprep_out)
path.plot(synth_out, dataprep_out)
path.plot
dataprep
View(texas)
dataprep_out <- dataprep(
foo = texas,
predictors = c("poverty", "income","crack"),
predictors.op = "mean",
time.predictors.prior = 1985:1993,
special.predictors = list(
list("bmprison", c(1988, 1990:1992), "mean"),
list("alcohol", 1990, "mean"),
list("aidscapita", 1990:1991, "mean"),
list("black", 1990:1992, "mean"),
list("perc1519", 1990, "mean")),
dependent = "bmprison",
unit.variable = "statefip",
unit.names.variable = "state",
time.variable = "year",
treatment.identifier = 48,
controls.identifier = c(1,2,4:6,8:13,15:42,44:47,49:51,53:56),
time.optimize.ssr = 1985:1993,
time.plot = 1985:2000
)
synth_out <- synth(data.prep.obj = dataprep_out)
path.plot(synth_out, dataprep_out)
dataprep_out <- dataprep(
foo = texas,
predictors = c("poverty", "income"),
predictors.op = "mean",
time.predictors.prior = 1985:1993,
special.predictors = list(
list("bmprison", c(1988, 1990:1992), "mean"),
list("alcohol", 1990, "mean"),
list("aidscapita", 1990:1991, "mean"),
list("black", 1990:1992, "mean"),
list("perc1519", 1990, "mean"),
list("crack", 1990, "mean")),
dependent = "bmprison",
unit.variable = "statefip",
unit.names.variable = "state",
time.variable = "year",
treatment.identifier = 48,
controls.identifier = c(1,2,4:6,8:13,15:42,44:47,49:51,53:56),
time.optimize.ssr = 1985:1993,
time.plot = 1985:2000
)
synth_out <- synth(data.prep.obj = dataprep_out)
path.plot(synth_out, dataprep_out)
dataprep_out <- dataprep(
foo = texas,
predictors = c("poverty", "income"),
predictors.op = "mean",
time.predictors.prior = 1985:1993,
special.predictors = list(
list("bmprison", c(1988, 1990:1992), "mean")),
dependent = "bmprison",
unit.variable = "statefip",
unit.names.variable = "state",
time.variable = "year",
treatment.identifier = 48,
controls.identifier = c(1,2,4:6,8:13,15:42,44:47,49:51,53:56),
time.optimize.ssr = 1985:1993,
time.plot = 1985:2000
)
synth_out <- synth(data.prep.obj = dataprep_out)
path.plot(synth_out, dataprep_out)
dataprep_out <- dataprep(
foo = texas,
predictors = c("income"),
predictors.op = "mean",
time.predictors.prior = 1985:1993,
special.predictors = list(
list("bmprison", c(1988, 1990:1992), "mean"),
list("alcohol", 1990, "mean"),
list("aidscapita", 1990:1991, "mean"),
list("black", 1990:1992, "mean"),
list("perc1519", 1990, "mean"),
list("crack", 1990, "mean")),
dependent = "bmprison",
unit.variable = "statefip",
unit.names.variable = "state",
time.variable = "year",
treatment.identifier = 48,
controls.identifier = c(1,2,4:6,8:13,15:42,44:47,49:51,53:56),
time.optimize.ssr = 1985:1993,
time.plot = 1985:2000
)
synth_out <- synth(data.prep.obj = dataprep_out)
path.plot(synth_out, dataprep_out)
dataprep_out <- dataprep(
foo = texas,
predictors = c("crack"),
predictors.op = "mean",
time.predictors.prior = 1985:1993,
special.predictors = list(
list("bmprison", c(1988, 1990:1992), "mean"),
list("alcohol", 1990, "mean"),
list("aidscapita", 1990:1991, "mean"),
list("black", 1990:1992, "mean"),
list("perc1519", 1990, "mean"),
list("crack", 1990, "mean")),
dependent = "bmprison",
unit.variable = "statefip",
unit.names.variable = "state",
time.variable = "year",
treatment.identifier = 48,
controls.identifier = c(1,2,4:6,8:13,15:42,44:47,49:51,53:56),
time.optimize.ssr = 1985:1993,
time.plot = 1985:2000
)
synth_out <- synth(data.prep.obj = dataprep_out)
path.plot(synth_out, dataprep_out)
dataprep_out <- dataprep(
foo = texas,
predictors = c("poverty", "income", "crack", "bmpop", "parole"),
predictors.op = "mean",
time.predictors.prior = 1985:1993,
special.predictors = list(
list("bmprison", c(1988, 1990:1992), "mean"),
list("alcohol", 1990, "mean"),
list("aidscapita", 1990:1991, "mean"),
list("black", 1990:1992, "mean"),
list("perc1519", 1990, "mean"),
list("crack", 1990, "mean")),
dependent = "bmprison",
unit.variable = "statefip",
unit.names.variable = "state",
time.variable = "year",
treatment.identifier = 48,
controls.identifier = c(1,2,4:6,8:13,15:42,44:47,49:51,53:56),
time.optimize.ssr = 1985:1993,
time.plot = 1985:2000
)
synth_out <- synth(data.prep.obj = dataprep_out)
path.plot(synth_out, dataprep_out)
dataprep_out <- dataprep(
foo = texas,
predictors = c("crack", "bmpop", "parole"),
predictors.op = "mean",
time.predictors.prior = 1985:1993,
special.predictors = list(
list("bmprison", c(1988, 1990:1992), "mean"),
list("poverty ", 1990, "mean"),
list("aidscapita", 1990:1991, "mean"),
list("income", 1990:1992, "mean"),
list("perc1519", 1990, "mean"),
list("crack", 1990, "mean")),
dependent = "bmprison",
unit.variable = "statefip",
unit.names.variable = "state",
time.variable = "year",
treatment.identifier = 48,
controls.identifier = c(1,2,4:6,8:13,15:42,44:47,49:51,53:56),
time.optimize.ssr = 1985:1993,
time.plot = 1985:2000
)
synth_out <- synth(data.prep.obj = dataprep_out)
path.plot(synth_out, dataprep_out)
dataprep_out <- dataprep(
foo = texas,
predictors = c("poverty", "income"),
predictors.op = "mean",
time.predictors.prior = 1985:1993,
special.predictors = list(
list("bmprison", c(1988, 1990:1992), "mean"),
list("alcohol", 1990, "mean"),
list("aidscapita", 1990:1991, "mean"),
list("black", 1990:1992, "mean"),
list("perc1519", 1990, "mean")),
dependent = "bmprison",
unit.variable = "statefip",
unit.names.variable = "state",
time.variable = "year",
treatment.identifier = 48,
controls.identifier = c(1,2,4:6,8:13,15:42,44:47,49:51,53:56),
time.optimize.ssr = 1985:1993,
time.plot = 1985:2000
)
synth_out <- synth(data.prep.obj = dataprep_out)
path.plot(synth_out, dataprep_out)
gaps.plot(synth_out, dataprep_out)
if(!require(installr)) {
install.packages("installr");
require(installr)
install.packages("installr")
0
0
)
install.packages("installr")
updateR()
library(installr)
updateR()
updater()
lib.paths
.lib.paths()
lib.paths()
library(geojsonio)
spdf <- geojson_read("https://raw.githubusercontent.com/gregoiredavid/france-geojson/master/communes.geojson",  what = "sp")
View(spdf)
spdf@data$mystate = substr( spdf@data$code, 1, 2)
spdf_region_6 = spdf[ spdf@data$mystate == "06" , ]
library(sp)
par(mar=c(0,0,0,0))
plot(spdf_region_6, col="grey")
library(broom)
library(broom)
spdf_fortified <- tidy(spdf_region_6)
# Plot it
library(ggplot2)
ggplot() +
geom_polygon(data = spdf_fortified, aes( x = long, y = lat, group = group), fill="#69b3a2", color="white") +
theme_void() +
coord_map()
gc()
setwd("~/GitHub/ECDS-Grp/GPG/longitudinal data")
library(haven)
lgwt22_5q_od21_od22_eul <- read_dta("lgwt22_5q_od21_od22_eul.dta")
View(lgwt22_5q_od21_od22_eul)
rm(list=ls())
library(haven)
lgwt22_5q_od21_od22_eul <- read_dta("lgwt22_5q_od21_od22_eul.dta")
View(lgwt22_5q_od21_od22_eul)
rm(list=ls())
library(haven)
long22 <- read_dta("lgwt22_5q_od21_od22_eul.dta")
View(long22l)
library(labelled)
look_for(long22, 'average hour')
look_for(long22, 'hour')
look_for(long22, 'sex'
0
look_for(long22, 'sex')
look_for(long22, 'birth')
look_for(long22, 'age')
look_for(long22, 'date')
look_for(long22, 'birth')
look_for(long22, 'year')
look_for(long22, 'date')
setwd("~/GitHub/ECDS-Grp/GPG/or cross section")
library(haven)
uk2014_y <- read_dta("uk2014_y.dta")
View(uk2014_y)
rm(list=ls())
rm(list=ls())
setwd("~/GitHub/ECDS-Grp/GPG/or cross section")
library(haven)
uk2014_y <- read_dta("uk2014_y.dta")
View(uk2014_y)
library(labelled)
uk2014 <- read_dta("uk2014_y.dta")
View(uk2014)
library(labelled)
look_for(uk2014, 'age')
look_for(uk2014, 'sex')
View(uk2014)
look_for(uk2014, 'hour')
look_for(uk2014, 'rate')
look_for(uk2014, 'pay')
